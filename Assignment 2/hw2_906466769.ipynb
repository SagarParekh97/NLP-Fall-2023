{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from copy import copy\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizerFast\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import f1_score, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read all relation labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 30 relations:\n",
      "0: /location/administrative_division/country\n",
      "1: /location/country/capital\n",
      "2: /location/country/administrative_divisions\n",
      "3: /location/neighborhood/neighborhood_of\n",
      "4: /location/location/contains\n",
      "5: /people/person/nationality\n",
      "6: /people/person/place_lived\n",
      "7: /people/deceased_person/place_of_death\n",
      "8: /business/person/company\n",
      "9: /location/us_state/capital\n",
      "10: /people/person/place_of_birth\n",
      "11: /people/person/children\n",
      "12: /business/company/founders\n",
      "13: /business/company/place_founded\n",
      "14: /sports/sports_team/location\n",
      "15: /people/person/ethnicity\n",
      "16: /people/ethnicity/geographic_distribution\n",
      "17: /people/person/religion\n",
      "18: /business/company/major_shareholders\n",
      "19: /location/province/capital\n",
      "20: /location/br_state/capital\n",
      "21: /business/company/advisors\n",
      "22: /film/film_location/featured_in_films\n",
      "23: /film/film/featured_film_locations\n",
      "24: /location/us_county/county_seat\n",
      "25: /time/event/locations\n",
      "26: /people/deceased_person/place_of_burial\n",
      "27: /people/place_of_interment/interred_here\n",
      "28: /business/company_advisor/companies_advised\n",
      "29: other\n"
     ]
    }
   ],
   "source": [
    "loc = './dataset/NYT29/relations.txt'\n",
    "relations = [f for f in open(loc, 'r').read().splitlines()]\n",
    "relations.append('other')\n",
    "RELATION_LABELS = {r: i for i, r in enumerate(relations)}\n",
    "LABEL2RELATION = {i: r for i, r in enumerate(relations)}\n",
    "\n",
    "print('Dataset contains {} relations:'.format(len(relations)))\n",
    "\n",
    "for k in RELATION_LABELS.keys():\n",
    "    print('{}: {}'.format(RELATION_LABELS[k], k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(relations)\n",
    "MODEL_NAME = 'bert-base-uncased'\n",
    "MAX_LEN = 128\n",
    "\n",
    "LR = 2e-5\n",
    "TRAINING_BATCH_SIZE = 16\n",
    "VAL_BATCH_SIZE = 1\n",
    "EPOCHS = 4\n",
    "DROPOUT = 0.3\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define dataset class for processing inputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_entity(entity_list):\n",
    "    if not isinstance(entity_list, list):\n",
    "        entity_list = [entity_list]\n",
    "    # remove white spaces and newline characters\n",
    "    for idx, e in enumerate(entity_list):\n",
    "        e = e.strip()\n",
    "        entity_list[idx] = e\n",
    "    return entity_list\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset_dict, tokenizer, max_len, add_CLS=True):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.sentences = dataset_dict['sent']\n",
    "        self.relation_tuples = dataset_dict['tup']\n",
    "        if len(self.sentences) != len(self.relation_tuples):\n",
    "            raise ValueError('The number of sentences and relation tuples are not equal.')\n",
    "        self.add_CLS = add_CLS\n",
    "        \n",
    "        self.separator = '|'\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # get the sentence and the corresponding relation tuple\n",
    "        sentence = self.sentences[index]\n",
    "        relation_tuples = self.relation_tuples[index]\n",
    "        relation_tuples = relation_tuples.split(self.separator)\n",
    "\n",
    "        # get all entities mentioned in the sentence\n",
    "        all_entity_pairs_mentioned = [clean_entity(x.split(';')[:2]) for x in relation_tuples]\n",
    "        all_entities = [item for sublist in all_entity_pairs_mentioned for item in sublist]\n",
    "        all_entities = {e: f'e_{i+1}' for i, e in enumerate(set(all_entities))}\n",
    "        all_possible_entity_pairs = [[x, y] for x in all_entities for y in all_entities if x != y]\n",
    "\n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "        target_labels = []\n",
    "        # e1_mask = []\n",
    "        # e2_mask = []\n",
    "        # position_ids_e1 = []\n",
    "        # position_ids_e2 = []\n",
    "\n",
    "        for entity_pair in all_possible_entity_pairs:\n",
    "            ent1, ent2 = entity_pair\n",
    "            positive_example_found = False\n",
    "            # positive examples\n",
    "            for er in relation_tuples:\n",
    "                entity1, entity2, relation = clean_entity(er.split(';'))\n",
    "                if ent1 != entity1 or ent2 != entity2:\n",
    "                    continue\n",
    "                marked_sentence = f\"[{all_entities[entity1]}]{entity1}[\\{all_entities[entity1]}] and \" \\\n",
    "                                f\"[{all_entities[entity2]}]{entity2}[\\{all_entities[entity2]}] have some relation in the context: {sentence}\"\n",
    "                encoding = self.tokenizer(marked_sentence, max_length=self.max_len, padding='max_length', \n",
    "                                          return_attention_mask=True, truncation=True, add_special_tokens=self.add_CLS,\n",
    "                                          return_tensors='pt')\n",
    "                input_ids.append(encoding['input_ids'])\n",
    "                attention_masks.append(encoding['attention_mask'])\n",
    "                target_labels.append(RELATION_LABELS[relation])\n",
    "                positive_example_found = True\n",
    "                break\n",
    "            if not positive_example_found:\n",
    "                # negative examples\n",
    "                entity1, entity2 = entity_pair\n",
    "                marked_sentence = f\"[{all_entities[entity1]}]{entity1}[\\{all_entities[entity1]}] and \" \\\n",
    "                                  f\"[{all_entities[entity2]}]{entity2}[\\{all_entities[entity2]}] have no relation in the context: {sentence}\"\n",
    "                encoding = self.tokenizer(marked_sentence, max_length=self.max_len, padding='max_length', \n",
    "                                          return_attention_mask=True, truncation=True, add_special_tokens=self.add_CLS,\n",
    "                                          return_tensors='pt')\n",
    "                input_ids.append(encoding['input_ids'])\n",
    "                attention_masks.append(encoding['attention_mask'])\n",
    "                target_labels.append(RELATION_LABELS['other'])\n",
    "\n",
    "        input_ids = torch.cat(input_ids, dim=0)\n",
    "        attention_masks = torch.cat(attention_masks, dim=0)\n",
    "        target_labels = torch.tensor(target_labels, dtype=torch.long)\n",
    "        return {'id': input_ids, 'mask': attention_masks, 'target': target_labels}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, dropout=0.3, num_classes=30):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.bertmodel = BertModel.from_pretrained(MODEL_NAME)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(self.bertmodel.config.hidden_size, num_classes)\n",
    "\n",
    "        self.loss_fcn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, ids, masks, targets, token_type_id=None, e1_mask=None, e2_mask=None, position_ids_e1=None, position_ids_e2=None):\n",
    "        outputs = self.bertmodel(ids, attention_mask=masks)\n",
    "        pooled_out = outputs[1]\n",
    "        pooled_out = self.dropout(pooled_out)\n",
    "        logits = self.classifier(pooled_out)\n",
    "        \n",
    "        _, prediction = torch.max(logits, dim=1)\n",
    "\n",
    "        loss = self.loss_fcn(logits, targets.view(-1))\n",
    "        return loss, prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = './dataset/NYT29/'\n",
    "\n",
    "file_types = ['.sent', '.tup']\n",
    "datasets = ['train', 'test', 'dev']\n",
    "\n",
    "train = {}\n",
    "test = {}\n",
    "dev = {}\n",
    "\n",
    "for d in datasets:\n",
    "    for t in file_types:\n",
    "        with open(os.path.join(dataset_dir, f'{d}{t}'), 'r') as f:\n",
    "            if t == '.sent':\n",
    "                exec(f'{d}[\"sent\"] = f.read().splitlines()')\n",
    "            else:\n",
    "                exec(f'{d}[\"tup\"] = f.read().splitlines()')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pretrained tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 63306\n",
      "Test dataset size: 4006\n",
      "Dev dataset size: 7033\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "\n",
    "train_dataset = Dataset(train, tokenizer, MAX_LEN)\n",
    "test_dataset = Dataset(test, tokenizer, MAX_LEN)\n",
    "dev_dataset = Dataset(dev, tokenizer, MAX_LEN)\n",
    "\n",
    "print('Train dataset size: {}'.format(len(train_dataset)))\n",
    "print('Test dataset size: {}'.format(len(test_dataset)))\n",
    "print('Dev dataset size: {}'.format(len(dev_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model, train_dataset_loader, dev_dataset_loader, optimizer, epochs, device):\n",
    "    ''' train '''\n",
    "    training_loss = []\n",
    "    training_accuracy = []\n",
    "    ''' validation '''\n",
    "    validation_loss = []\n",
    "    validation_accuracy = []\n",
    "    for e in range(epochs):\n",
    "        train_sample_count = 0\n",
    "        correct_predictions = 0\n",
    "        model.train()\n",
    "        for data in tqdm(train_dataset_loader, leave=False):\n",
    "            ids = data['id'].to(device)\n",
    "            masks = data['mask'].to(device)\n",
    "            targets = data['target'].to(device)\n",
    "            # e1_mask = data['e1_mask'].to(device)\n",
    "            # e2_mask = data['e2_mask'].to(device)\n",
    "            # position_ids_e1 = data['position_ids_e1'].to(device)\n",
    "            # position_ids_e2 = data['position_ids_e2'].to(device)\n",
    "\n",
    "            loss, prediction = model(ids=ids, masks=masks, targets=targets)\n",
    "                                    #  e1_mask=e1_mask, e2_mask=e2_mask, \n",
    "                                    #  position_ids_e1=position_ids_e1, position_ids_e2=position_ids_e2)\n",
    "            training_loss.append(loss.item())\n",
    "            correct_predictions += torch.sum(prediction == targets).cpu().detach().numpy()\n",
    "            train_sample_count += len(targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        training_accuracy.append((e, correct_predictions / train_sample_count))\n",
    "\n",
    "        model.eval()\n",
    "        val_sample_count = 0\n",
    "        correct_predictions = 0\n",
    "        for data in tqdm(dev_dataset_loader):\n",
    "            ids = data['id'].to(device)\n",
    "            masks = data['mask'].to(device)\n",
    "            targets = data['target'].to(device)\n",
    "\n",
    "            loss, prediction = model(ids, masks, targets)\n",
    "            validation_loss.append(loss.item())\n",
    "            correct_predictions += torch.sum(prediction == targets).cpu().detach().numpy()\n",
    "            val_sample_count += len(targets)\n",
    "            \n",
    "        validation_accuracy.append((e, correct_predictions / val_sample_count))    \n",
    "\n",
    "        tqdm.write(f'Epoch: {e}, Training loss: {np.mean(training_loss)}, Training accuracy: {sum(list(zip(*training_accuracy))[1])},' \\\n",
    "                   f' Validation loss: {np.mean(validation_loss)}, Validation accuracy: {sum(list(zip(*validation_accuracy))[1])}')\n",
    "\n",
    "    # save the trained models\n",
    "    model_checkpoint = dict()\n",
    "    model_checkpoint['model_state_dict'] = model.state_dict()\n",
    "    model_checkpoint['optimizer_state_dict'] = optimizer.state_dict()\n",
    "    model_checkpoint['training_loss'] = training_loss\n",
    "    model_checkpoint['training_accuracy'] = training_accuracy\n",
    "    model_checkpoint['validation_loss'] = validation_loss\n",
    "    model_checkpoint['validation_accuracy'] = validation_accuracy\n",
    "    torch.save(model_checkpoint, f'./save_data/model_checkpoint.pth')\n",
    "    return training_loss, training_accuracy, validation_loss, validation_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define collate function for dataloader**\n",
    "\n",
    "Need to define how to stack batches since different sentences can have different lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fcn(batch):\n",
    "    return {'id': torch.cat([x['id'] for x in batch], dim=0),\n",
    "            'mask': torch.cat([x['mask'] for x in batch], dim=0),\n",
    "            'target': torch.cat([x['target'] for x in batch], dim=0)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the dataset loaders to pass to the training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dataLoader = {'batch_size': TRAINING_BATCH_SIZE,\n",
    "                     'shuffle': True,\n",
    "                     'num_workers': NUM_WORKERS,\n",
    "                     'collate_fn': collate_fcn}\n",
    "train_dataset_loader = torch.utils.data.DataLoader(train_dataset, **params_dataLoader)\n",
    "\n",
    "params_dataLoader_eval = {'batch_size': VAL_BATCH_SIZE,\n",
    "                          'shuffle': True,\n",
    "                          'num_workers': 0,\n",
    "                          'collate_fn': collate_fcn}\n",
    "dev_dataset_loader = torch.utils.data.DataLoader(dev_dataset, **params_dataLoader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize model and optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier(dropout=DROPOUT, num_classes=NUM_CLASSES).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sagar-legion/Projects/NLP-Fall-2023/Assignment 2/hw2_906466769.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/sagar-legion/Projects/NLP-Fall-2023/Assignment%202/hw2_906466769.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(\u001b[39m'\u001b[39m\u001b[39msave_data/\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/sagar-legion/Projects/NLP-Fall-2023/Assignment%202/hw2_906466769.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(\u001b[39m'\u001b[39m\u001b[39msave_data\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/sagar-legion/Projects/NLP-Fall-2023/Assignment%202/hw2_906466769.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m training_loss, training_accuracy, validation_loss, validation_accuracy \u001b[39m=\u001b[39m trainer(model, train_dataset_loader, dev_dataset_loader, optimizer, EPOCHS, device)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/sagar-legion/Projects/NLP-Fall-2023/Assignment%202/hw2_906466769.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m fname \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./save_data/training_loss.json\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/sagar-legion/Projects/NLP-Fall-2023/Assignment%202/hw2_906466769.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(fname, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "\u001b[1;32m/home/sagar-legion/Projects/NLP-Fall-2023/Assignment 2/hw2_906466769.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/sagar-legion/Projects/NLP-Fall-2023/Assignment%202/hw2_906466769.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m     train_sample_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(targets)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/sagar-legion/Projects/NLP-Fall-2023/Assignment%202/hw2_906466769.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/sagar-legion/Projects/NLP-Fall-2023/Assignment%202/hw2_906466769.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/sagar-legion/Projects/NLP-Fall-2023/Assignment%202/hw2_906466769.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/sagar-legion/Projects/NLP-Fall-2023/Assignment%202/hw2_906466769.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m training_accuracy\u001b[39m.\u001b[39mappend((e, correct_predictions \u001b[39m/\u001b[39m train_sample_count))\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_hw1/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_hw1/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "load = all([os.path.exists(f'save_data/{f}') for f in ['model_checkpoint.pth', 'training_loss.json', 'training_accuracy.json']])\n",
    "\n",
    "if load:\n",
    "    model_dir = 'save_data/model_checkpoint.pth'\n",
    "    model_checkpoint = torch.load(model_dir)\n",
    "    model.load_state_dict(model_checkpoint['model_state_dict'])\n",
    "\n",
    "    fname = os.path.join(f'./save_data/training_loss.json')\n",
    "    with open(fname, 'r') as f:\n",
    "        training_loss = json.load(f)\n",
    "    fname = os.path.join(f'./save_data/training_accuracy.json')\n",
    "    with open(fname, 'r') as f:\n",
    "        training_accuracy = json.load(f)\n",
    "    fname = os.path.join(f'./save_data/validation_loss.json')\n",
    "    with open(fname, 'r') as f:\n",
    "        validation_loss = json.load(f)\n",
    "    fname = os.path.join(f'./save_data/validation_accuracy.json')\n",
    "    with open(fname, 'r') as f:\n",
    "        validation_accuracy = json.load(f)\n",
    "else:\n",
    "    if not os.path.exists('save_data/'):\n",
    "        os.makedirs('save_data')\n",
    "    training_loss, training_accuracy, validation_loss, validation_accuracy = trainer(model, train_dataset_loader, dev_dataset_loader, optimizer, EPOCHS, device)\n",
    "\n",
    "    fname = os.path.join(f'./save_data/training_loss.json')\n",
    "    with open(fname, 'w') as f:\n",
    "        json.dump(training_loss, f)\n",
    "    fname = os.path.join(f'./save_data/training_accuracy.json')\n",
    "    with open(fname, 'w') as f:\n",
    "        json.dump(training_accuracy, f)\n",
    "    fname = os.path.join(f'./save_data/validation_loss.json')\n",
    "    with open(fname, 'w') as f:\n",
    "        json.dump(validation_loss, f)\n",
    "    fname = os.path.join(f'./save_data/validation_accuracy.json')\n",
    "    with open(fname, 'w') as f:\n",
    "        json.dump(validation_accuracy, f)\n",
    "\n",
    "_, ax = plt.subplots(2, 2, figsize=(10, 8))\n",
    "ax[0, 0].plot(training_loss, marker='.')\n",
    "ax[0, 0].set_title('Training Loss')\n",
    "ax[0, 1].plot(*zip(*training_accuracy))\n",
    "ax[0, 1].set_title('Training Accuracy')\n",
    "ax[1, 0].plot(validation_loss, marker='.')\n",
    "ax[1, 0].set_title('Validation Loss')\n",
    "ax[1, 1].plot(*zip(*validation_accuracy))\n",
    "ax[1, 1].set_title('Validation Accuracy')\n",
    "\n",
    "ax[0, 1].set_ylim([0, 1])\n",
    "ax[1, 1].set_ylim([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script for evaluating the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, dataset_loader, params_dataLoader, device):\n",
    "    y_pred = np.empty(0)\n",
    "    y_true = np.empty(0)\n",
    "    for i, data in enumerate(tqdm(dataset_loader)):\n",
    "        ids = data['id'].to(device)\n",
    "        masks = data['mask'].to(device)\n",
    "        targets = data['target'].to(device)\n",
    "\n",
    "        y_true = np.concatenate((y_true, targets.cpu().detach().numpy()))\n",
    "        with torch.no_grad():\n",
    "            _, prediction = model(ids, masks, targets)\n",
    "            y_pred = np.concatenate((y_pred, prediction.cpu().detach().numpy()))\n",
    "    \n",
    "    pred_relation = [LABEL2RELATION[p] for p in y_pred]\n",
    "    true_relation = [LABEL2RELATION[p] for p in y_true]\n",
    "    report = f1_score(true_relation, pred_relation, labels=list(LABEL2RELATION.values()), average='micro')\n",
    "\n",
    "    print('Micro Average F1-Score: {}'.format(report))\n",
    "\n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate the trained classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Test set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [00:39<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Average F1-Score: 0.9192520186995325\n"
     ]
    }
   ],
   "source": [
    "params_dataLoader_eval = {'batch_size': VAL_BATCH_SIZE,\n",
    "                          'shuffle': False,\n",
    "                          'num_workers': 0,\n",
    "                          'collate_fn': collate_fcn}\n",
    "test_dataset_loader = torch.utils.data.DataLoader(test_dataset, **params_dataLoader)\n",
    "\n",
    "print('-- Test set:')\n",
    "test_report = eval(model, test_dataset_loader, params_dataLoader_eval, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Dev set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 440/440 [01:08<00:00,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Average F1-Score: 0.9875261152759002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "params_dataLoader_eval = {'batch_size': VAL_BATCH_SIZE,\n",
    "                          'shuffle': False,\n",
    "                          'num_workers': 0,\n",
    "                          'collate_fn': collate_fcn}\n",
    "dev_dataset_loader = torch.utils.data.DataLoader(dev_dataset, **params_dataLoader)\n",
    "\n",
    "print('-- Dev set:')\n",
    "test_report = eval(model, dev_dataset_loader, params_dataLoader_eval, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Train set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3957/3957 [09:55<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Average F1-Score: 0.9976635833253631\n"
     ]
    }
   ],
   "source": [
    "params_dataLoader_eval = {'batch_size': VAL_BATCH_SIZE,\n",
    "                          'shuffle': False,\n",
    "                          'num_workers': 0,\n",
    "                          'collate_fn': collate_fcn}\n",
    "train_dataset_loader = torch.utils.data.DataLoader(train_dataset, **params_dataLoader)\n",
    "\n",
    "print('-- Train set:')\n",
    "train_report = eval(model, train_dataset_loader, params_dataLoader_eval, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the output in a pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook hw2_906466769.ipynb to pdf\n",
      "[NbConvertApp] Support files will be in hw2_906466769_Output_files/\n",
      "[NbConvertApp] Making directory ./hw2_906466769_Output_files\n",
      "[NbConvertApp] Writing 73835 bytes to notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', 'notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 126693 bytes to hw2_906466769_Output.pdf\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "import subprocess\n",
    "\n",
    "subprocess.call('jupyter nbconvert hw2_906466769.ipynb --to pdf --output hw2_906466769_Output.pdf', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_hw1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
