{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from copy import copy\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import time \n",
    "\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CHOICES = 4\n",
    "MODEL_NAME = 'bert-base-uncased'\n",
    "MAX_LEN = 128\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "LR = 1e-5\n",
    "TRAINING_BATCH_SIZE = 8\n",
    "VAL_BATCH_SIZE = 1\n",
    "EPOCHS = 5\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 25262\n",
      "Test dataset size: 6963\n",
      "Dev dataset size: 2985\n"
     ]
    }
   ],
   "source": [
    "loc = './dataset/'\n",
    "\n",
    "train = pd.read_csv(loc + 'train.csv')\n",
    "test = pd.read_json(loc + 'test.jsonl', lines=True)\n",
    "val = pd.read_csv(loc + 'valid.csv')\n",
    "\n",
    "print('Train dataset size: {}'.format(len(train)))\n",
    "print('Test dataset size: {}'.format(len(test)))\n",
    "print('Dev dataset size: {}'.format(len(val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define collate function for dataloader**\n",
    "\n",
    "Need to define how to stack batches since different sentences can have different lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_device(*args):\n",
    "    return (item.to(DEVICE) \n",
    "            if isinstance(item, torch.Tensor) \n",
    "            else item\n",
    "            for item in args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fcn(batch):\n",
    "    ids = [x['id'] for x in batch]\n",
    "    features = [x['features'] for x in batch]\n",
    "    tokens_batch, input_ids_batch, input_masks_batch, token_type_ids_batch, p_len_batch, q_len_batch, a_len_batch = ([] for _ in range(7))\n",
    "    # read the batch of features\n",
    "    for f_i in features:\n",
    "        tokens, input_ids, input_masks, token_type_ids, p_len, q_len, a_len = ([] for _ in range(7))\n",
    "        # each feature item has 4 datapoints for the four options\n",
    "        for f in f_i:\n",
    "            tokens.append(f[0])\n",
    "            input_ids.append(f[1])\n",
    "            input_masks.append(f[2])\n",
    "            token_type_ids.append(f[3])\n",
    "            p_len.append(f[4])\n",
    "            q_len.append(f[5])\n",
    "            a_len.append(f[6])\n",
    "        tokens_batch.append(tokens)\n",
    "        input_ids_batch.append(input_ids)\n",
    "        input_masks_batch.append(input_masks)\n",
    "        token_type_ids_batch.append(token_type_ids)\n",
    "        p_len_batch.append(p_len)\n",
    "        q_len_batch.append(q_len)\n",
    "        a_len_batch.append(a_len)\n",
    "    input_ids_batch = torch.tensor(input_ids_batch, dtype=torch.long)\n",
    "    input_masks_batch = torch.tensor(input_masks_batch, dtype=torch.long)\n",
    "    token_type_ids_batch = torch.tensor(token_type_ids_batch, dtype=torch.long)\n",
    "    p_len_batch = torch.tensor(p_len_batch, dtype=torch.long)\n",
    "    q_len_batch = torch.tensor(q_len_batch, dtype=torch.long)\n",
    "    a_len_batch = torch.tensor(a_len_batch, dtype=torch.long)\n",
    "    labels = torch.tensor([x['label'] for x in batch], dtype=torch.long)\n",
    "\n",
    "    return ids, tokens_batch, input_ids_batch, input_masks_batch, token_type_ids_batch, p_len_batch, q_len_batch, a_len_batch, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len, add_CLS=True):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.add_CLS = add_CLS\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _truncate_seq(self, seq_1, seq_2, max_length):\n",
    "        ''' Truncate a sequence pair in place to keep the combined length = maximum length. \n",
    "            Always truncate the longer sequence. '''\n",
    "        while True:\n",
    "            total_len = len(seq_1) + len(seq_2)\n",
    "            if total_len <= max_length:\n",
    "                break\n",
    "            if len(seq_1) > len(seq_2):\n",
    "                seq_1.pop()\n",
    "            else:\n",
    "                seq_2.pop()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        id = row['id']\n",
    "        context = row['context']\n",
    "        question = row['question']\n",
    "        options = [row['answer0'], row['answer1'], row['answer2'], row['answer3']]\n",
    "        correct_opt = row['label']\n",
    "        \n",
    "        # take care of the case where the option is None\n",
    "        options = [str(opt) if not isinstance(opt, str) else opt for opt in options]\n",
    "\n",
    "        feature_set = []\n",
    "        context_tokens = self.tokenizer.tokenize(context)\n",
    "        question_tokens = self.tokenizer.tokenize(question)\n",
    "        for opt in options:\n",
    "            context_tokens_copy = copy(context_tokens)\n",
    "\n",
    "            opt_tokens = self.tokenizer.tokenize(opt)\n",
    "            q_opt_tok = question_tokens + opt_tokens\n",
    "\n",
    "            # truncate the context and question + option if they are too long\n",
    "            self._truncate_seq(context_tokens_copy, q_opt_tok, self.max_len - 3)\n",
    "\n",
    "            ''' [CLS] context [SEP] question option [SEP] '''\n",
    "            ''' [ 0      0      0      1       1      1 ] '''\n",
    "            tokens = ['[CLS]'] + context_tokens_copy + ['[SEP]'] + q_opt_tok + ['[SEP]']\n",
    "            token_type_ids = [0] * (len(context_tokens_copy) + 2) + [1] * (len(q_opt_tok) + 1)\n",
    "            \n",
    "            input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "            input_masks = [1] * len(input_ids)\n",
    "\n",
    "            # pad the tokens to max length\n",
    "            padding_length = self.max_len - len(input_ids)\n",
    "            padding = [0] * padding_length\n",
    "            input_ids += padding\n",
    "            input_masks += padding\n",
    "            token_type_ids += padding\n",
    "\n",
    "            assert len(input_ids) == self.max_len, \"Input ids should be {}, but is {} instead\".format(self.max_len, len(input_ids))\n",
    "            assert len(input_masks) == self.max_len, \"Input masks should be {}, but is {} instead\".format(self.max_len, len(input_masks))\n",
    "            assert len(token_type_ids) == self.max_len, \"Token type ids should be {}, but is {} instead\".format(self.max_len, len(token_type_ids))\n",
    "\n",
    "            feature_set.append((tokens, input_ids, input_masks, token_type_ids,\n",
    "                                len(context_tokens_copy), len(question_tokens), len(opt_tokens)))\n",
    "\n",
    "        return {'id': id,\n",
    "                'features': feature_set,\n",
    "                'label': correct_opt}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture for Question-Answering\n",
    "To enhance the context understanding ability of BERT fine-tuning, we perform multiway bidirectional attention over the BERT encoding output. The model architecture is adopted from **DCMN+: Dual Co-Matching Network for Multi-choice Reading Comprehension** [(arxiv)](https://arxiv.org/pdf/1908.11511.pdf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Single_matchNet(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Single_matchNet, self).__init__()\n",
    "        self.trans_linear = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "\n",
    "    def forward(self, p_proj, q_proj, p_att, q_att):\n",
    "        p_trans = self.trans_linear(p_proj)\n",
    "        q_trans = self.trans_linear(q_proj)\n",
    "        p2q_score = torch.matmul(p_trans, q_trans.transpose(2, 1))\n",
    "\n",
    "        merged_p2q_att = p_att.unsqueeze(2).float().matmul(q_att.unsqueeze(1).float())\n",
    "        merged_p2q_att = merged_p2q_att.to(dtype=next(self.parameters()).dtype)\n",
    "        merged_p2q_att = (1.0 - merged_p2q_att) * -10000.0\n",
    "\n",
    "        p2q_score_ = p2q_score + merged_p2q_att\n",
    "        # normalize the attention scores to probabilities\n",
    "        p2q_w = nn.Softmax(dim=-1)(p2q_score_)\n",
    "        p2q_w_ = nn.Softmax(dim=1)(p2q_score_)\n",
    "\n",
    "        # question attentive passage representation\n",
    "        mp = torch.matmul(p2q_w, q_proj)\n",
    "        # passage attentive question representation\n",
    "        mq = torch.matmul(p2q_w_.transpose(2, 1), p_proj)\n",
    "\n",
    "        return mp, mq\n",
    "        \n",
    "class Fuse_net(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Fuse_net, self).__init__()\n",
    "        self.linear1 = nn.Linear(2 * config.hidden_size, config.hidden_size)\n",
    "        self.linear2 = nn.Linear(2 * config.hidden_size, config.hidden_size)\n",
    "        self.linear3 = nn.Linear(2 * config.hidden_size, config.hidden_size)\n",
    "\n",
    "    def forward(self, p_seq, mp_q, mp_a, mp_qa, q_seq, mq_p, mq_a, mq_pa, a_seq, ma_p, ma_q, ma_pq):\n",
    "        new_mp_q = torch.cat([mp_q - p_seq, mp_q * p_seq], dim=2)\n",
    "        new_mp_a = torch.cat([mp_a - p_seq, mp_a * p_seq], dim=2)\n",
    "        new_mp_qa = torch.cat([mp_qa - p_seq, mp_qa * p_seq], dim=2)\n",
    "        new_mq_p = torch.cat([mq_p - q_seq, mq_p * q_seq], dim=2)\n",
    "        new_mq_a = torch.cat([mq_a - q_seq, mq_a * q_seq], 2)\n",
    "        new_mq_pa = torch.cat([mq_pa - q_seq, mq_pa * q_seq], 2)\n",
    "        new_ma_p = torch.cat([ma_p - a_seq, ma_p * a_seq], 2)\n",
    "        new_ma_q = torch.cat([ma_q - a_seq, ma_q * a_seq], 2)\n",
    "        new_ma_pq = torch.cat([ma_pq - a_seq, ma_pq * a_seq], 2)\n",
    "\n",
    "        new_mp = torch.cat([new_mp_q, new_mp_a, new_mp_qa], dim=1)\n",
    "        new_mq = torch.cat([new_mq_p, new_mq_a, new_mq_pa], dim=1)\n",
    "        new_ma = torch.cat([new_ma_p, new_ma_q, new_ma_pq], dim=1)\n",
    "\n",
    "        new_mp_ = nn.functional.relu(self.linear1(new_mp))\n",
    "        new_mq_ = nn.functional.relu(self.linear2(new_mq))\n",
    "        new_ma_ = nn.functional.relu(self.linear3(new_ma))\n",
    "\n",
    "        new_p_max, new_p_idx = torch.max(new_mp_, dim=1)\n",
    "        new_q_max, new_q_idx = torch.max(new_mq_, dim=1)\n",
    "        new_a_max, new_a_idx = torch.max(new_ma_, dim=1)\n",
    "\n",
    "        new_p_max_ = new_p_max.view(-1, NUM_CHOICES, new_p_max.size(1))\n",
    "        new_q_max_ = new_q_max.view(-1, NUM_CHOICES, new_q_max.size(1))\n",
    "        new_a_max_ = new_a_max.view(-1, NUM_CHOICES, new_a_max.size(1))\n",
    "\n",
    "        c = torch.cat([new_p_max_, new_q_max_, new_a_max_], dim=2)\n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_seq(sequence_output, p_len, q_len, a_len):\n",
    "    p_seq_output = sequence_output.new(sequence_output.size()).zero_()\n",
    "    q_seq_output = sequence_output.new(sequence_output.size()).zero_()\n",
    "    a_seq_output = sequence_output.new(sequence_output.size()).zero_()\n",
    "    p_q_seq_output = sequence_output.new(sequence_output.size()).zero_()\n",
    "    q_a_seq_output = sequence_output.new(sequence_output.size()).zero_()\n",
    "    p_a_seq_output = sequence_output.new(sequence_output.size()).zero_()\n",
    "    for i in range(p_len.size(0)):\n",
    "        p_seq_output[i, :p_len[i]] = sequence_output[i, 1:p_len[i] + 1]\n",
    "        q_seq_output[i, :q_len[i]] = sequence_output[i, p_len[i] + 2:p_len[i] + 2 + q_len[i]]\n",
    "        a_seq_output[i, :a_len[i]] = sequence_output[i, p_len[i] + q_len[i] + 2:p_len[i] + q_len[i] + 2 + a_len[i]]\n",
    "\n",
    "        p_q_seq_output[i, :p_len[i]] = sequence_output[i, 1:p_len[i] + 1]\n",
    "        p_q_seq_output[i, p_len[i]:p_len[i] + q_len[i]] = sequence_output[i, p_len[i] + 2:p_len[i] + 2 + q_len[i]]\n",
    "\n",
    "        q_a_seq_output[i, :q_len[i]] = sequence_output[i, p_len[i] + 2:p_len[i] + 2 + q_len[i]]\n",
    "        q_a_seq_output[i, q_len[i]:q_len[i] + a_len[i]] = sequence_output[i, p_len[i] + q_len[i] + 2:p_len[i] + q_len[i] + 2 + a_len[i]]\n",
    "\n",
    "        p_a_seq_output[i, :p_len[i]] = sequence_output[i, 1:p_len[i] + 1]\n",
    "        p_a_seq_output[i, p_len[i]:p_len[i] + a_len[i]] = sequence_output[i, p_len[i] + q_len[i] + 2:p_len[i] + q_len[i] + 2 + a_len[i]]\n",
    "    \n",
    "    return p_seq_output, q_seq_output, a_seq_output, p_q_seq_output, q_a_seq_output, p_a_seq_output\n",
    "\n",
    "def separate_attmask(flat_att_mask, p_len, q_len, a_len):\n",
    "    p_seq_output = flat_att_mask.new(flat_att_mask.size()).zero_()\n",
    "    q_seq_output = flat_att_mask.new(flat_att_mask.size()).zero_()\n",
    "    a_seq_output = flat_att_mask.new(flat_att_mask.size()).zero_()\n",
    "    p_q_seq_output = flat_att_mask.new(flat_att_mask.size()).zero_()\n",
    "    q_a_seq_output = flat_att_mask.new(flat_att_mask.size()).zero_()\n",
    "    p_a_seq_output = flat_att_mask.new(flat_att_mask.size()).zero_()\n",
    "    for i in range(p_len.size(0)):\n",
    "        p_seq_output[i, :p_len[i]] = flat_att_mask[i, 1:p_len[i] + 1]\n",
    "        q_seq_output[i, :q_len[i]] = flat_att_mask[i, p_len[i] + 2:p_len[i] + 2 + q_len[i]]\n",
    "        a_seq_output[i, :a_len[i]] = flat_att_mask[i, p_len[i] + q_len[i] + 2:p_len[i] + q_len[i] + 2 + a_len[i]]\n",
    "\n",
    "        p_q_seq_output[i, :p_len[i]] = flat_att_mask[i, 1:p_len[i] + 1]\n",
    "        p_q_seq_output[i, p_len[i]:p_len[i] + q_len[i]] = flat_att_mask[i, p_len[i] + 2:p_len[i] + 2 + q_len[i]]\n",
    "\n",
    "        q_a_seq_output[i, :q_len[i]] = flat_att_mask[i, p_len[i] + 2:p_len[i] + 2 + q_len[i]]\n",
    "        q_a_seq_output[i, q_len[i]:q_len[i] + a_len[i]] = flat_att_mask[i, p_len[i] + q_len[i] + 2:p_len[i] + q_len[i] + 2 + a_len[i]]\n",
    "\n",
    "        p_a_seq_output[i, :p_len[i]] = flat_att_mask[i, 1:p_len[i] + 1]\n",
    "        p_a_seq_output[i, p_len[i]:p_len[i] + a_len[i]] = flat_att_mask[i, p_len[i] + q_len[i] + 2:p_len[i] + q_len[i] + 2 + a_len[i]]\n",
    "    \n",
    "    return p_seq_output, q_seq_output, a_seq_output, p_q_seq_output, q_a_seq_output, p_a_seq_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_multChoice(nn.Module):\n",
    "    def __init__(self, hidden_size=None):\n",
    "        super(BERT_multChoice, self).__init__()\n",
    "\n",
    "        self.bert_encoder = BertModel.from_pretrained(MODEL_NAME)\n",
    "        if hidden_size is None:\n",
    "            hidden_size = self.bert_encoder.config.hidden_size\n",
    "        self.classifier = nn.Linear(hidden_size * 3, 1)\n",
    "        self.ssmatch = Single_matchNet(self.bert_encoder.config)\n",
    "        self.fuse = Fuse_net(self.bert_encoder.config)\n",
    "\n",
    "        self.loss_fcn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids, attention_mask, p_len, q_len, a_len, labels):\n",
    "        # flatten the inputs\n",
    "        flat_input_ids = input_ids.view(-1, input_ids.shape[-1])\n",
    "        flat_token_type_ids = token_type_ids.view(-1, token_type_ids.shape[-1])\n",
    "        flat_attention_mask = attention_mask.view(-1, attention_mask.shape[-1])\n",
    "        p_len = p_len.view(-1, p_len.shape[0] * p_len.shape[1]).squeeze()\n",
    "        q_len = q_len.view(-1, q_len.shape[0] * q_len.shape[1]).squeeze()\n",
    "        a_len = a_len.view(-1, a_len.shape[0] * a_len.shape[1]).squeeze()\n",
    "\n",
    "        output = self.bert_encoder(input_ids=flat_input_ids, token_type_ids=flat_token_type_ids, \n",
    "                                   attention_mask=flat_attention_mask, return_dict=True,\n",
    "                                   encoder_hidden_states=True)\n",
    "        pooled_output = output[\"pooler_output\"]\n",
    "        sequence_output = output[\"last_hidden_state\"]\n",
    "\n",
    "        p_seq_output, q_seq_output, a_seq_output, p_q_seq_output, q_a_seq_output, p_a_seq_output = \\\n",
    "            separate_seq(sequence_output, p_len, q_len, a_len)\n",
    "\n",
    "        p_att_mask, q_att_mask, a_att_mask, p_q_att_mask, q_a_att_mask, p_a_att_mask = \\\n",
    "            separate_attmask(flat_attention_mask, p_len, q_len, a_len)\n",
    "\n",
    "        mp_q, mq_p = self.ssmatch(p_seq_output, q_seq_output, p_att_mask, q_att_mask)\n",
    "        mq_a, ma_q = self.ssmatch(q_seq_output, a_seq_output, q_att_mask, a_att_mask)\n",
    "        mp_a, ma_p = self.ssmatch(p_seq_output, a_seq_output, p_att_mask, a_att_mask)\n",
    "        mp_qa, mqa_p = self.ssmatch(p_seq_output, q_a_seq_output, p_att_mask, q_a_att_mask)\n",
    "        mq_pa, mpa_q = self.ssmatch(q_seq_output, p_a_seq_output, q_att_mask, p_a_att_mask)\n",
    "        ma_pq, mpq_a = self.ssmatch(a_seq_output, p_q_seq_output, a_att_mask, p_q_att_mask)\n",
    "\n",
    "        c = self.fuse(p_seq_output, mp_q, mp_a, mp_qa, q_seq_output, mq_p, mq_a, mq_pa, a_seq_output, ma_p, ma_q, ma_pq)\n",
    "\n",
    "        c_ = c.view(-1, c.size(2))\n",
    "        logits = self.classifier(c_)\n",
    "        logits = logits.view(-1, NUM_CHOICES)\n",
    "\n",
    "        logits_copy = logits.clone().detach().cpu().numpy()\n",
    "        prediction = np.argmax(logits_copy, axis=1)\n",
    "\n",
    "        loss = self.loss(logits, labels)\n",
    "        return loss, prediction\n",
    "    \n",
    "    def loss(self, logits, label):\n",
    "        return self.loss_fcn(logits, label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the training loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model, optimizer, train_loader, val_loader):\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # tensorboard\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    training_loss = []\n",
    "    training_accuracy = []\n",
    "    validation_loss = []\n",
    "    validation_accuracy = []\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        correct_predictions = 0\n",
    "        train_sample_count = 0\n",
    "\n",
    "        ''' training '''\n",
    "        model.train()\n",
    "        tic = time.time()\n",
    "        for i, batch in enumerate(tqdm(train_loader, desc='Training', ncols=100, leave=False)):\n",
    "            ids, tokens_batch, input_ids_batch, input_masks_batch, token_type_ids_batch, \\\n",
    "                p_len_batch, q_len_batch, a_len_batch, labels = send_to_device(*batch)\n",
    "\n",
    "            loss, prediction = model(input_ids_batch, token_type_ids_batch, input_masks_batch, \n",
    "                                p_len_batch, q_len_batch, a_len_batch, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            labels = labels.cpu().numpy()\n",
    "            correct_predictions += np.sum(prediction == labels)\n",
    "            training_loss.append(loss.item())\n",
    "            train_sample_count += len(input_ids_batch)\n",
    "\n",
    "            # write to tensorboard\n",
    "            writer.add_scalar('Loss/train', loss.item(), epoch * len(train_loader) + i)\n",
    "            writer.add_scalar('Accuracy/train', np.sum(prediction == labels) / len(input_ids_batch), epoch * len(train_loader) + i)\n",
    "        \n",
    "        training_accuracy.append((epoch, correct_predictions / train_sample_count))\n",
    "\n",
    "        ''' validation '''\n",
    "        val_sample_count = 0\n",
    "        correct_predictions = 0\n",
    "        \n",
    "        model.eval()\n",
    "        for j, data in enumerate(tqdm(val_loader, desc='Validation', ncols=100, leave=False)):\n",
    "            ids, tokens_batch, input_ids_batch, input_masks_batch, token_type_ids_batch, \\\n",
    "                p_len_batch, q_len_batch, a_len_batch, labels = send_to_device(*data)\n",
    "\n",
    "            loss, prediction = model(input_ids_batch, token_type_ids_batch, input_masks_batch, \n",
    "                                     p_len_batch, q_len_batch, a_len_batch, labels)\n",
    "            \n",
    "            validation_loss.append(loss.item())\n",
    "            correct_predictions += np.sum(prediction == labels)\n",
    "            val_sample_count += len(input_ids_batch)\n",
    "\n",
    "            # write to tensorboard\n",
    "            writer.add_scalar('Loss/val', loss.item(), epoch * len(val_loader) + j)\n",
    "            writer.add_scalar('Accuracy/val', np.sum(prediction == labels) / len(input_ids_batch), epoch * len(val_loader) + j)\n",
    "\n",
    "        validation_accuracy.append((epoch, correct_predictions / val_sample_count))    \n",
    "\n",
    "        tqdm.write(f'Epoch: {epoch}, Training time: {time.time() - tic} s, Training loss: {np.mean(training_loss)}, Training accuracy: {sum(list(zip(*training_accuracy))[1])},' \\\n",
    "                   f' Validation loss: {np.mean(validation_loss)}, Validation accuracy: {sum(list(zip(*validation_accuracy))[1])}')\n",
    "\n",
    "    # save the trained models\n",
    "    model_checkpoint = dict()\n",
    "    model_checkpoint['model_state_dict'] = model.state_dict()\n",
    "    model_checkpoint['optimizer_state_dict'] = optimizer.state_dict()\n",
    "    model_checkpoint['training_loss'] = training_loss\n",
    "    model_checkpoint['training_accuracy'] = training_accuracy\n",
    "    model_checkpoint['validation_loss'] = validation_loss\n",
    "    model_checkpoint['validation_accuracy'] = validation_accuracy\n",
    "    torch.save(model_checkpoint, f'./save_data/model_checkpoint.pth')\n",
    "    \n",
    "    \n",
    "    return training_loss, training_accuracy, validation_loss, validation_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train, tokenizer, MAX_LEN)\n",
    "val_dataset = Dataset(val, tokenizer, MAX_LEN)\n",
    "test_dataset = Dataset(test, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dataLoader = {'batch_size': TRAINING_BATCH_SIZE,\n",
    "                     'shuffle': True,\n",
    "                     'num_workers': NUM_WORKERS,\n",
    "                     'collate_fn': collate_fcn}\n",
    "train_dataset_loader = torch.utils.data.DataLoader(train_dataset, **params_dataLoader)\n",
    "\n",
    "params_dataLoader = {'batch_size': VAL_BATCH_SIZE,\n",
    "                     'shuffle': True,\n",
    "                     'num_workers': 0,\n",
    "                     'collate_fn': collate_fcn}\n",
    "val_dataset_loader = torch.utils.data.DataLoader(val_dataset, **params_dataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT_multChoice().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|██                                                | 130/3158 [01:28<33:06,  1.52it/s]"
     ]
    }
   ],
   "source": [
    "load = all([os.path.exists(f'save_data/{f}') for f in ['model_checkpoint.pth', 'training_loss.json', 'training_accuracy.json',\n",
    "                                                       'validation_loss.json', 'validation_accuracy.json']])\n",
    "\n",
    "if load:\n",
    "    model_dir = 'save_data/model_checkpoint.pth'\n",
    "    model_checkpoint = torch.load(model_dir)\n",
    "    model.load_state_dict(model_checkpoint['model_state_dict'])\n",
    "\n",
    "    fname = os.path.join(f'./save_data/training_loss.json')\n",
    "    with open(fname, 'r') as f:\n",
    "        training_loss = json.load(f)\n",
    "    fname = os.path.join(f'./save_data/training_accuracy.json')\n",
    "    with open(fname, 'r') as f:\n",
    "        training_accuracy = json.load(f)\n",
    "    fname = os.path.join(f'./save_data/validation_loss.json')\n",
    "    with open(fname, 'r') as f:\n",
    "        validation_loss = json.load(f)\n",
    "    fname = os.path.join(f'./save_data/validation_accuracy.json')\n",
    "    with open(fname, 'r') as f:\n",
    "        validation_accuracy = json.load(f)\n",
    "else:\n",
    "    os.makedirs('save_data', exist_ok=True)\n",
    "    training_loss, training_accuracy, validation_loss, validation_accuracy = trainer(model, optimizer, train_dataset_loader, val_dataset_loader)\n",
    "\n",
    "    fname = os.path.join(f'./save_data/training_loss.json')\n",
    "    with open(fname, 'w') as f:\n",
    "        json.dump(training_loss, f)\n",
    "    fname = os.path.join(f'./save_data/training_accuracy.json')\n",
    "    with open(fname, 'w') as f:\n",
    "        json.dump(training_accuracy, f)\n",
    "    fname = os.path.join(f'./save_data/validation_loss.json')\n",
    "    with open(fname, 'w') as f:\n",
    "        json.dump(validation_loss, f)\n",
    "    fname = os.path.join(f'./save_data/validation_accuracy.json')\n",
    "    with open(fname, 'w') as f:\n",
    "        json.dump(validation_accuracy, f)\n",
    "\n",
    "_, ax = plt.subplots(2, 2, figsize=(10, 8))\n",
    "ax[0, 0].plot(training_loss, marker='.')\n",
    "ax[0, 0].set_title('Training Loss')\n",
    "ax[0, 1].plot(*zip(*training_accuracy))\n",
    "ax[0, 1].set_title('Training Accuracy')\n",
    "ax[1, 0].plot(validation_loss, marker='.')\n",
    "ax[1, 0].set_title('Validation Loss')\n",
    "ax[1, 1].plot(*zip(*validation_accuracy))\n",
    "ax[1, 1].set_title('Validation Accuracy')\n",
    "\n",
    "ax[0, 1].set_ylim([0, 1])\n",
    "ax[1, 1].set_ylim([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_hw1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
